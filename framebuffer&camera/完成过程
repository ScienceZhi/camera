作者：科技植 QQ:806329586
其中错别字请谅解
一、项目描述
1、硬件平台：S5PV210开发板，PC（主机ubuntu16.04）
2、软件平台：linux(直接基于Linux API)
3、实现基于Linux API直接操作framebuffer和UVC摄像头，将拍摄到的画面实时显示在开发板的屏幕上

二、重点难点
1、对实现过程中相关资料的查找与参考。在前期筛选参考资料的过程中，筛选出来以下3个网址：
		1）http://blog.sina.com.cn/s/blog_602f87700100znq7.html	 嵌入式Linux下Camera编程--V4L2
		2）http://blog.csdn.net/zhaocj/article/details/38404521     基于S3C2440的Linux-3.6.6移植——基于UVC的USB摄像头移植及视频显示 
		3）http://blog.chinaunix.net/uid-26696487-id-3076027.html	 mini2440 usb摄像头程序详解
   以上网址中，讲到的知识点或者对代码的解释既有相同的也有不同还有没提及的，对实现视频显示的方式也不尽相同。我在其中就得不断重复的进行分析、判断、采纳、实践等工作

三、遇到的问题
问题1：
	在第一个网址链接中，只讲述到了创建一组缓冲区(buf)，并不完整
解决过程：
	1、使用了第二条和第三条网址作为相互补充和佐证，并检查了第一条网址中，先前的全部代码与第二三条网址的做法步骤是否有较大出入或不同



问题2：
	在初次写代码时，linux给摄像头创建的设备文件名为/dev/video3。第二天linux分配给摄像头的文件名为/dev/video0。这造成，运行代码时一直无法通过。报错信息显示/dev/video3不是一个图像采集设备(V4L2_BUF_TYPE_VIDEO_CAPTURE)。
解决过程：
	1、一开始本人怀疑是摄像头坏了。于是将摄像头从S5PV210开发板上取下，插入安装着 ubuntu 16.04的笔记本电脑，并运行系统自带的茄子大头贴应用。根据运行结果，可判断摄像头并没损坏。于是我又用gcc命令编译了写好的c程序(此时我已根据ubuntu中分配给摄像头的文件名/dev/video1对c程序进行了修改)，程序正常运行，显示该设备是一个图像采集设备。然而改回/dev/video3后，装回开发板，再次运行，依旧失败。  
	2、在各种怀疑与猜测下，我拿出了以前购买的GL-AR150路由器(由GL-inet生产)，将摄像头插入路由器，并通过以前自己制作好的gl-ar150交叉编译工具链将c编译链接(同上，此时修改了对应的设备文件名)，用scp命令将可执行文件发给路由器，再用ssh命令登录路由器，运行该程序，结果表明该设备是一个图像采集设备。为了再次确定摄像头能在路由器上正常使用，我网页登录了路由器提供的管理界面，运行了页面提供的mjpeg-stream程序。发现在网页上能正常实时显示摄像头拍摄到的画面。
	3、关闭路由器，并经过一番思考，我决定去查查摄像头插在开发板上时，linux分配给它的设备文件名是否正确。结果比对，发现此时Linux分配给摄像头的文件名为/dev/video0。这让我苦笑不得。
思考原因：
		经验证发现，一开始我是先开启开发板上的linux系统，等linux系统正常启动完毕后，才插上的uvc usb摄像头，系统给它分配的设备文件名为/dev/video3。后续的开发中，摄像头并没有从开发板上拔下，发现它被分配到的设备文件名为/dev/video0



问题3：
	在参考网上资料的过程中，发现现有的3个网址提供的信息不足以满足后续的开发要求或者说对整个开发过程提供的思路不清晰
解决过程：
		1、在网上继续查找资料，找到如下网址：http://www.cnblogs.com/surpassal/archive/2012/12/19/zed_webcam_lab1.html
		2、在认真阅读和对比以前网址里的内容后，发现，这篇博客讲得更详细和深入(我使用到的包含他的(1)(2)(3)篇)，于是整合了前面已有代码，并在后面开发中使用了该博客提供的思路，当然这篇博客提供了源码下载



问题4：
	在参考问题3中提及的博客的过程中，按照这篇博客的思路，先提取一帧画面将其像素点转换成rgb888并添加头文件和头信息后生成一张bmp格式的图片，后面的实时显示建立在这一步的基础上。但本人参考这代码并多次修改和尝试后生成的bmp图片一直是全黑的
解决过程：
	1、该博客提供了源码，下载后，运行它的源码，发现能生成一张正常的拍摄到的bmp格式的图片。仔细对比源码并进行相应部分的替换，编译运行替换后的代码
	2、经过第一步后发现，在源码中，包含了一个作者自己写的头文件，其中定义了bmp图片的头文件和头信息结构体。但在这些结构体代码之前有这样一句本人没见过的代码 “#pragma pack(1)”。有这句代码就能生成正常的bmp图片，没有则生成全黑的bmp图片。
	3、于是本人去百度了“#pragma pack(1)”的作用，百度解释为#pragma pack(1)让编译器将结构体数据强制连续排列，这让我想起且意识到了，编译器为了高效运行，在结构体里会使用四字节对齐的方式，这导致了本人代码中生成的bmp图片的头信息所占用的字节有问题，所以生成的bmp图片为全黑。
	4、在代码中添加#pragma pack(1)后，就能生成正常的bmp图片


问题5：
	第一次动态显示时，显示图像与拍摄图片为镜像对称，且rgb相反
解决过程：	
	1、更换像素点的显示方向，从原来的从左至右变为从右至左。变换rgb中r和b的位置

问题6：
	第一次实现动态显示时，画面卡钝严重，严重至大概两秒才一帧画面
解决过程：
	1、根据已掌握的对图像采集的相关知识，进行猜想与假设可能导致画面卡钝的原因。
	2、思考后认为最有可能影响卡钝的原因就是缓冲区不够多，于是在使用VIDIOC_REQBUFS申请缓冲区时，将申请数量由4改成了10，发现画面变得更卡钝。
	3、将申请数量由4个改为1个，发现换面相对流畅多了，虽然还是稍有延迟，不过在能接受的范围内。
	4、在已经修改好的基础上，思考还有可能影响画面稍有延迟的原因。初步认为是像素太大，于是将代码中的640*480像素换成了320*240像素，运行结果显示段错误
	5、在一番查了缓冲区大小，显示函数等问题后，发现问题最有可能出在yuyv_2_rgb888()函数中，于是参照原本的yuyv_2_rgb888()函数，修改里边值为640或480为对应的320*240，并使用宏定义来提高阅读性，再次编译运行，程序正常工作，肉眼基本看不出延迟，类似车载摄像头工作时的效果

————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————
编写过程：

1.搜索嵌入式Linux下Camera编程 uvc格式摄像头等关键词

2.相关有用链接 http://blog.sina.com.cn/s/blog_602f87700100znq7.html	 嵌入式Linux下Camera编程--V4L2
		http://blog.csdn.net/zhaocj/article/details/38404521     基于S3C2440的Linux-3.6.6移植——基于UVC的USB摄像头移植及视频显示 
		http://blog.chinaunix.net/uid-26696487-id-3076027.html	 mini2440 usb摄像头程序详解
		http://www.cnblogs.com/surpassal/archive/2012/12/19/zed_webcam_lab1.html (原创)基于ZedBoard的Webcam设计(一)：USB摄像头(V4L2接口)的图片采集 这里记录得最为详细，讲解知识点最为全面。代码的最终制作步骤和这篇网址里几乎一致

3.对链接做如下相关记录
背景知识
首先要确认的是，Kernel是否支持USB Camera。因为Linux下，USB协议除了电气协议和标准，还有很多Class。 这些Class就是为了支持和定义某一类设备接口和交互数据格式。只要符合这类标准，则不同厂商的USB设备，不需要特定的driver就能在Linux下使用。
例如：USB Input class,则使所有输入设备都可以直接使用。还有类似Audio Class， Pring Class，Mass Storage Class， video class等。
其中Video Class 就是我们常说的UVC（USB Video Class）. 只要USB Camera符合UVC标准。理论上在2.6 Kernel Linux 就可以正常使用。	


Kernel配置
Device Drivers  --->  <*> Multimedia support  --->  <*>   Video For Linux
Device Drivers  --->  <*> Multimedia support  ---> [*]   Video capture adapters  --->  [*]   V4L USB devices  --->    <*>   USB Video Class (UVC)

